{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of IFT6760-H20-A1-Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreeadeac22/IFT6760H20/blob/master/Copy_of_IFT6760_H20_A1_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM9fD394B_Pe",
        "colab_type": "text"
      },
      "source": [
        "This synthetic MDP has no particular meaning except that it produces pretty plot. It is inspired from [Dadashi & al. (2019)](http://proceedings.mlr.press/v97/dadashi19a.html).\n",
        "\n",
        "Note: we will be using [JAX](https://jax.readthedocs.io/en/latest/) instead of Numpy because we will later make use of the automatic differentiation feature. \n",
        "Because JAX is meant to work best when the code is properly [*jitted*](https://en.wikipedia.org/wiki/Just-in-time_compilation) (which I didn't do for simplicity), some sections may run slower than a pure Numpy implementation. It shouldn't be a problem for the problems that we are working with (order of few seconds max). If you are impatient, feel free to use the [@jit](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit) decorator where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqvBWr_ROOgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "def synthetic_mdp():\n",
        "  P = np.array([[[0.75 , 0.25 ], [0.2 , 0.8 ]],\n",
        "                [[0.99, 0.01], [0.8, 0.2]]])\n",
        "  mdp_R = np.array(([[-0.5, -0.25 ],\n",
        "                [ 0.5 ,  0.25 ]]))\n",
        "  return P, mdp_R, 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Ra2WWSBj20",
        "colab_type": "text"
      },
      "source": [
        "The method of successive approximation provides us with a generic template for all of our algorithms. In the following, we will use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRSuNAuEPOQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_iterates(xinit, operator, termination_condition):\n",
        "    x, xprev = operator(xinit), xinit\n",
        "    #print(x)\n",
        "    yield x\n",
        "    while not termination_condition(xprev, x):\n",
        "        x, xprev = operator(x), x\n",
        "        yield x\n",
        "\n",
        "def successive_approximation(xinit, operator=lambda x: x, termination_condition=lambda xprev, x: False):\n",
        "    for iterate in generate_iterates(xinit, operator, termination_condition):\n",
        "      pass\n",
        "    return iterate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzlHLc5YKKR3",
        "colab_type": "text"
      },
      "source": [
        "We define a generic termination condition for successive approximation based on the Euclidean distance between two iterates. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXkVO95t6ERS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def default_termination(xprev, x, epsilon=1e-8):\n",
        "  return np.linalg.norm(xprev - x) < epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUkjR0Ak9H0X",
        "colab_type": "text"
      },
      "source": [
        "# Policy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nblOb8_RJQOp",
        "colab_type": "text"
      },
      "source": [
        "We start by implementing the policy evaluation operator. Refer to the section on vector notation in the course notes or read Puterman (1994) for references. \n",
        "In general, many of these operations can be written consicely by using [np.einsum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html). For an overview of Einstein notation, see this [blogpost](https://rockt.github.io/2018/04/30/einsum) by Tim RocktÃ¤schel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsF5eokZOhxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_policy_evaluation_operator(P, R, discount, policy):\n",
        "  def policy_evaluation_operator(v):  \n",
        "    p_pi = np.einsum('ijk,ji->jk', P, policy)\n",
        "    discounted_pv = discount * np.einsum('ij,j->i', p_pi, v)\n",
        "    r_pi = np.einsum('ij, ij -> i', policy, R)\n",
        "    return np.add(r_pi, discounted_pv)\n",
        "  return policy_evaluation_operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A61DGS9zPPW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdp = synthetic_mdp()\n",
        "P, mdp_R, discount = mdp\n",
        "nstates, nactions = P.shape[-1], P.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iam11W2I7Jor",
        "colab_type": "text"
      },
      "source": [
        "A good sanity check to see if our policy evaluation method is to use a reward function which is $1$ everywhere. In the discounted setting, we have that the expected return should be equal to $1/(1- \n",
        "\\gamma)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgRmfX6x5Qyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a589e9d0-713e-4cf1-e0f5-a9576734b644"
      },
      "source": [
        "reward_all_ones = np.ones((nstates, nactions))\n",
        "uniform_policy = np.ones((nstates, nactions))/nactions\n",
        "\n",
        "policy_evaluation_operator = make_policy_evaluation_operator(P, reward_all_ones, discount, uniform_policy)\n",
        "solution = successive_approximation(np.zeros((nstates,)), policy_evaluation_operator, default_termination)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfs7k0_n731a",
        "colab_type": "text"
      },
      "source": [
        "The following should return true:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nHxm0XA7fae",
        "colab_type": "code",
        "outputId": "f583baea-8cb0-4ee6-bdf7-4c619341d4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(solution, [1/(1-discount)]*nstates)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzBiQoj48Div",
        "colab_type": "text"
      },
      "source": [
        "Now we can also make sure that the solution found by succesive approximation matches the closed-form solution which we would obtain using a direct method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asgiFX-z8C8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def direct_policy_evaluation(P, R, discount, policy):\n",
        "  # Add your implementation below. Avoid explicit matrix inverses\n",
        "  # You should be able to do this in 3 lines or less.\n",
        "  p_pi = np.einsum('ijk,ji->jk', P, policy)\n",
        "  #print(\"p_pi \", p_pi)\n",
        "  discounted_p_pi = discount * p_pi\n",
        "  a = np.subtract(np.identity(P.shape[-1]), discounted_p_pi)\n",
        "  #print(\"a \", a)\n",
        "\n",
        "  r_pi = np.einsum('ij, ij -> i', policy, R)\n",
        "  #print(\"r_pi \", r_pi)\n",
        "  return np.linalg.solve(a, r_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBPMSD58qex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "solution = direct_policy_evaluation(P, reward_all_ones, discount, uniform_policy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebRl21Rk88EU",
        "colab_type": "text"
      },
      "source": [
        "This should once again return true: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yySrLUSO8-BH",
        "colab_type": "code",
        "outputId": "297ff74d-9c83-49a8-d427-891c44496608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(solution, [1/(1-discount)]*nstates)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdYO4Pk7SA2",
        "colab_type": "text"
      },
      "source": [
        "## Projected Policy Evaluation Operator\n",
        "\n",
        "We have seen that the projected policy evaluation equations can be solved either in closed form or iteratively using the projected (Bellman) policy evaluation operator. \n",
        "\n",
        "Because the projection is taken with respect to a weighted Euclidean distance, you have to compute the entries of the diagonal matrix $X$ by solving for the stationary distribution of the given policy in the MDP. \n",
        "\n",
        "Remember that a stationary distribution $x$ must satisfy $x^\\top P = x^\\top$, \n",
        "where $x^\\top \\mathbf{1} = 1 \\in \\mathbb{R}^{|\\mathcal{S}|}$ and $P \\in \\mathbb{R}^{|\\mathcal{S}| \\times |\\mathcal{S}|}$. Therfore, $x^\\top$ is a left eigenvector of $P$. By the [Perron-Frobenius theorem](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem), we know that there exists a eigenvalue of maximum modulus which is a real positive number: the Perron root. For stochastic matrices, the Perron root (the spectral radis) is equal to 1. Furthermore, the eigenvector associated with the Perron root (the Perron vector) has only positive components. \n",
        "\n",
        "You can use numpy to find the eigendecomposition of the stochastic matrix, isolate the Perron vector (through the Perron root) and normalize the resulting vector so that it sums up to one. \n",
        "\n",
        "Alternatively, you could also choose to view the problem of finding a solution to $x^\\top P = x^\\top$ as a fixed-point problem and use the above ``successive_approximation`` function with the appropriate operator. Note however that the zero vector is a trivial solution of this problem, and you should make sure not to initialize from this point.\n",
        "\n",
        "In the following, implement a function to compute the stationary distribution for a given transition matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPQsu8DMtfdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stationary_distribution(P):\n",
        "  # Compute stationary distribution here\n",
        "  w, v = np.linalg.eig(P.T)\n",
        "  for i, e in enumerate(w):\n",
        "    if np.isclose(e, 1.):\n",
        "      return v[:,i] / np.sum(v[:,i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp4olEZDtiiX",
        "colab_type": "text"
      },
      "source": [
        "We can now use this function to pre-compute the stationary distribution and use it to form the projected policy evaluation operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s9_7Pc4PtB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_pvi_operator(P, R, discount, policy, phi):\n",
        "  # Compute A and b matrices here\n",
        "  p_pi = np.einsum('ijk,ji->jk', P, policy)\n",
        "\n",
        "  x = stationary_distribution(p_pi) \n",
        "  phitx = np.einsum('ij,jk->ik', phi.T, np.diag(x))\n",
        "\n",
        "  a = np.subtract(np.identity(P.shape[-1]), discount * p_pi)\n",
        "  phitx_a = np.einsum('ij, jk->ik', phitx, a)\n",
        "  A = np.einsum('ij, jk->ik', phitx_a, phi)\n",
        "\n",
        "  r_pi = np.einsum('ij, ij -> i', policy, R)\n",
        "  b = np.einsum('ij, j->i', phitx, r_pi)\n",
        "\n",
        "  def pvi_operator(w):\n",
        "    # Compute projection here, without forming matrix inverse explicitely\n",
        "    phitx_phi = np.einsum('ij, jk->ik', phitx, phi)\n",
        "    c_wk = np.einsum('ij, j->i', phitx_phi, w)\n",
        "\n",
        "    A_wk = np.einsum('ij, j->i', A, w)\n",
        "\n",
        "    rhs = np.subtract( np.add(c_wk, b), A_wk)\n",
        "    return np.linalg.solve(phitx_phi, rhs)\n",
        "  return pvi_operator  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhkXt45ROshY",
        "colab_type": "text"
      },
      "source": [
        "As a sanity check, we can verify that we obtain the exact solution when using *one-hot*  (tabular) features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpDJX2HE7g8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_features = np.eye(nstates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyV5tIUS7cN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2566d58-32d8-477a-8015-e9424e9fefe5"
      },
      "source": [
        "pvi_operator = make_pvi_operator(P, reward_all_ones, discount, uniform_policy, one_hot_features)\n",
        "solution = successive_approximation(np.zeros(nstates), pvi_operator, default_termination)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.+0.j 1.+0.j]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO-O2CcN7rPP",
        "colab_type": "text"
      },
      "source": [
        "Because we used the reward function which is one everywhere, we should also find that the expected return is $1/(1-\\gamma)$. \n",
        "\n",
        "This test should also return true:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDr6icJh7ulj",
        "colab_type": "code",
        "outputId": "23c4bb7d-4c1d-4e83-aa90-e1af4f671656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(one_hot_features @ solution, [1/(1-discount)]*nstates)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXzvaE3sv8c3",
        "colab_type": "text"
      },
      "source": [
        "A non-iterative alternative to the above PVI algorithm is simply to solve for the projected policy evaluation equations using a direct method. Implement the projected counterpart to the above ``direct_policy_evaluation`` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV52XImau62l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def direct_projected_policy_evaluation(P, R, discount, policy, phi):\n",
        "  # Compute A and b matrices here\n",
        "  p_pi = np.einsum('ijk,ji->jk', P, policy)\n",
        "\n",
        "  x = stationary_distribution(p_pi) \n",
        "  phitx = np.einsum('ij,jk->ik', phi.T, np.diag(x))\n",
        "\n",
        "  a = np.subtract(np.identity(P.shape[-1]), discount*p_pi)\n",
        "  phitx_a = np.einsum('ij, jk->ik', phitx, a)\n",
        "  A = np.einsum('ij, jk->ik', phitx_a, phi)\n",
        "\n",
        "  r_pi = np.einsum('ij, ij -> i', policy, R)\n",
        "  b = np.einsum('ij, j->i', phitx, r_pi)\n",
        "  return np.linalg.solve(A, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJWu8bOxvrlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "solution = direct_projected_policy_evaluation(P, reward_all_ones, discount, uniform_policy, one_hot_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ocbZkcv6pV",
        "colab_type": "code",
        "outputId": "55140c29-24a2-470a-f699-ad417ae8fe12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(one_hot_features @ solution, [1/(1-discount)]*nstates)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absD_AHc6Hr2",
        "colab_type": "text"
      },
      "source": [
        "### Bertsekas Bound\n",
        "\n",
        "Verify that the bound in proposition 6.3.1 for Bertsekas holds. Use the direct of iterative policy evaluation methods to compute all the terms in the bound. \n",
        "\n",
        "Test for the synthetic MDP with a uniform policy and tabular features. Then generate a random full-rank matrix of features and repeat the exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKSjhO1f4ci-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verifying Bertsekas bound\n",
        "\n",
        "\n",
        "# solution = direct_policy_evaluation(P, reward_all_ones, discount, uniform_policy)\n",
        "# projected_solution = direct_projected_policy_evaluation(P, reward_all_ones, discount, uniform_policy, one_hot_features)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyMzMoLO9OWt",
        "colab_type": "text"
      },
      "source": [
        "# Optimality Equations\n",
        "\n",
        "As usual, I advise you to use [np.einsum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html) to implement the following optimality operators. Note that in all cases, the following operators act on vectors $v \\in \\mathbb{R}^{|\\mathcal{S}|}$ and not on Q-factors $Q \\in \\mathbb{R}^{|\\mathcal{S}|\\times|\\mathcal{A}|}$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wobqDMBU9Yd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bellman_optimality_operator(P, R, discount):\n",
        "  def bellman_optimality_operator(v):\n",
        "    # This should be a one-liner\n",
        "    #print(\"P \", P)\n",
        "    #print(\"R \", R)\n",
        "    return np.max(np.add(R, discount * np.einsum('ijk,k->ji', P, v)), axis=1)\n",
        "  return bellman_optimality_operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7VKL_yRRmNn",
        "colab_type": "text"
      },
      "source": [
        "Now do the same thing but where you use the [soft-max](https://en.wikipedia.org/wiki/Smooth_maximum) (smooth maximum) instead of the *hard* one. You can use the built-in implementations of the soft-max function for more stability. See [Rust (1996)](https://doi.org/10.1016/s1574-0021(96)01016-7) for reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiM5UyHqPSRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax.experimental.stax import softmax\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "def make_smooth_bellman_optimality_operator(P, R, discount, temperature):\n",
        "  def smooth_bellman_optimality_operator(v):\n",
        "    # This should be a one-liner\n",
        "    \n",
        "    #softmaxed = softmax(1./temperature * v)\n",
        "    #softmaxed_v = np.einsum('i,i->i', softmaxed, v)\n",
        "    #r_pv = np.sum(np.add(R, discount * np.einsum('ijk,k->ji', P, softmaxed_v)), axis=-1)\n",
        "    #print(\"P \", P)\n",
        "    #print(\"v \", v)\n",
        "    pv = np.einsum('ijk,k->ji', P, v)\n",
        "    #print(\"pv \", pv)\n",
        "    r_pv = np.add(R, discount * pv)\n",
        "    #print(\"r_pv \", r_pv)\n",
        "    #print(\"r_pv \", r_pv)\n",
        "    temp_lv = 1./temperature * r_pv  \n",
        "    #print(\"temp_lv \", temp_lv)\n",
        "    max_col = np.reshape(np.max(temp_lv, axis=1), newshape=(nstates, 1))\n",
        "    #print(\"max_col \", max_col)\n",
        "    max_mat = np.repeat(max_col, repeats=temp_lv.shape[0], axis=1)\n",
        "    shift_templv =  temp_lv - max_mat\n",
        "    #print(\"shift \", shift_templv)\n",
        "    #s = np.max(temp_lv) + np.log(np.sum(np.exp(shift_templv), axis=1))\n",
        "    s = np.max(temp_lv, axis=1) + np.log(np.sum(np.exp(shift_templv), axis=1))\n",
        "    #print(\"s \", s)\n",
        "    #ss = logsumexp(r_pv, axis=-1, b=1./temperature)\n",
        "    #print(\"ss \", ss)\n",
        "    #print(\"new s \", temperature * s)\n",
        "    return temperature * s\n",
        "  return smooth_bellman_optimality_operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4jtWev0BHKR",
        "colab_type": "text"
      },
      "source": [
        "We can apply the same sanity check for the optimality equations and use a reward function where all components are set to $1$. The following loop goes over the *hard* and smooth optimality operators and verifies that we recover the optimal value function in all cases:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpeftUNq-Q8o",
        "colab_type": "code",
        "outputId": "9857dc7b-226c-417a-b0ce-c029da86ae6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "default_temperature = 1e-5\n",
        "\n",
        "hard_operator = make_bellman_optimality_operator(P, reward_all_ones, discount)\n",
        "smooth_operator = make_smooth_bellman_optimality_operator(P, reward_all_ones, discount, default_temperature)\n",
        "\n",
        "for operator in [hard_operator, smooth_operator]:\n",
        "  solution = successive_approximation(np.zeros((nstates,)), operator, default_termination)\n",
        "  print(np.allclose(solution, [1/(1-discount)]*nstates))"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1.]\n",
            "True\n",
            "[1.00000693 1.00000693]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSc1mIstWHGD",
        "colab_type": "text"
      },
      "source": [
        "Equipped with policy evaluation methods from above, we can also easily define a policy evaluation operator. Note that this time, the operator takes a policy (not a value vector) and returns an improved policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVM5q4rtWQtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_policy_iteration_operator(P, R, discount):\n",
        "  def policy_iteration_operator(policy):\n",
        "    v = direct_policy_evaluation(P, R, discount, policy)\n",
        "    argmax_a = np.argmax(np.add(R, discount * np.einsum('ijk,k->ji', P, v)), axis=1)\n",
        "    return np.eye(P.shape[-1])[argmax_a]\n",
        "  return policy_iteration_operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJbSf-pEkl4N",
        "colab_type": "text"
      },
      "source": [
        "We also have to define a new termination condition, suited to the fact that we iterate over deterministic policies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbvP63qokiPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_iteration_termination(policy_prev, policy):\n",
        "  return np.allclose(policy_prev, policy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzV3W9xkx1x",
        "colab_type": "text"
      },
      "source": [
        "In a somewhat redundant exercise, you can also define the smooth counterpart to the usual policy iteration by replacing the argmax with the soft-argmax. You can also use a built-in implementation for better numerical stability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCzlaZsykjRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax.nn import softmax\n",
        "def make_smooth_policy_iteration_operator(P, R, discount, temperature):\n",
        "  def smooth_policy_iteration_operator(policy):\n",
        "    v = direct_policy_evaluation(P, R, discount, policy)\n",
        "\n",
        "    pv = np.einsum('ijk,k->ji', P, v)\n",
        "\n",
        "    temp_lv = 1./temperature * np.add(R, discount*pv)\n",
        "    #normalized = np.exp(temp_lv - temp_lv.max())\n",
        "    #new_policy = temp_lv / np.sum(temp_lv, axis=0)\n",
        "    #return temp_lv / np.sum(temp_lv, axis=0)\n",
        "    return  softmax(temp_lv)\n",
        "  return smooth_policy_iteration_operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4ViwtCKlBFq",
        "colab_type": "text"
      },
      "source": [
        "The method of sucessive approximation applied to these operators returns a policy as output, if we want to verify that they are indeed optimal, we now need to re-use our policy evaluation code to compute the associated value function.\n",
        "\n",
        "The following should return true twice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SrQ2ZEZZb73",
        "colab_type": "code",
        "outputId": "ec754312-08b1-430f-cd48-0551e0de5c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "policy_iteration_operator = make_policy_iteration_operator(P, reward_all_ones, discount)\n",
        "policy = successive_approximation(np.zeros((nstates, nactions)), policy_iteration_operator, policy_iteration_termination)\n",
        "solution = direct_policy_evaluation(P, reward_all_ones, discount, policy)\n",
        "print(np.allclose(solution, [1/(1-discount)]*nstates))"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oqbEfFplicW",
        "colab_type": "code",
        "outputId": "3f2dbe05-12f3-4fb5-a53e-2ea97b565645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "smooth_policy_iteration_operator = make_smooth_policy_iteration_operator(P, reward_all_ones, discount, default_temperature)\n",
        "policy = successive_approximation(np.zeros((nstates, nactions)), smooth_policy_iteration_operator, default_termination)\n",
        "solution = direct_policy_evaluation(P, reward_all_ones, discount, policy)\n",
        "print(np.allclose(solution, [1/(1-discount)]*nstates))"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06KXVif-wzlR",
        "colab_type": "text"
      },
      "source": [
        "## Newton-Kantorovich\n",
        "\n",
        "In order to implement Newton-Kantorovich for the smooth Bellman operator, we first use the analytical expression for its Gateaux derivative. See [Rust (1996)](https://doi.org/10.1016/s1574-0021(96)01016-7) for reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwaLGLLYOrZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax.experimental.stax import softmax\n",
        "\n",
        "def make_gateaux_derivative(P, R, discount, temperature):\n",
        "  \"\"\" Returns the Gateaux derivative at v of the smooth Bellman operator\n",
        "  \"\"\"\n",
        "  def gateaux_at(v):\n",
        "    \"\"\" Binds v into a function computing the gateaux derivative\n",
        "    \"\"\"\n",
        "    #print(\"P \", P)\n",
        "    pv = np.einsum('ijk,k->ji', P, v)\n",
        "    #print(\"pv \", pv)\n",
        "    d = softmax(1./temperature * np.add(R, discount*pv))\n",
        "    #print(\"d \", d)\n",
        "    def gateaux_direction(w):\n",
        "      \"\"\" Compute the Gateaux derivative at v in the direction of w\n",
        "      \"\"\"\n",
        "      # Add your code here\n",
        "      pw = np.einsum('ijk,k->ji', P, w)\n",
        "      #print(\"pw \", pw)\n",
        "      d_pw = np.einsum('ij, ij -> i', d, pw)\n",
        "      #print(\"d_pw \", d_pw)\n",
        "      return discount * d_pw \n",
        "    return gateaux_direction\n",
        "  return gateaux_at"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJOeFmVzPOLo",
        "colab_type": "text"
      },
      "source": [
        "We can also compute this derivative using forward-mode automatic differentiation in [JAX](https://github.com/google/jax). Under the hood, forward-mode automatic differentiation is implemented by defining the jacobian-vector for all primitive operations. This vector-jacobian product corresponds to our notion of directional derivative and the function [vjp](https://jax.readthedocs.io/en/latest/jax.html#jax.jvp) gives us that.\n",
        "\n",
        "The following should return true:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eno-wKxSDa6Y",
        "colab_type": "code",
        "outputId": "f5e1cf29-dd5b-4444-f59c-bdee3cf08d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from jax import jvp\n",
        "\n",
        "v = np.ones(nstates)/nstates\n",
        "w = np.array([1.,2.])\n",
        "\n",
        "_, tangents = jvp(smooth_operator, (v, ), (w,))\n",
        "deriv = make_gateaux_derivative(P, reward_all_ones, discount, default_temperature)(v)(w)\n",
        "\n",
        "print(\"tangents \", tangents)\n",
        "print(\"deriv \", deriv)\n",
        "np.allclose(tangents, deriv)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tangents  [1.017 1.35 ]\n",
            "deriv  [1.017 1.35 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwx2GuDETxbX",
        "colab_type": "text"
      },
      "source": [
        "Equipped with the Gateaux derivative, we can then implement the Newton-Kantorovich algorithm in a generic way. Because Newton-Kantorovich involves taking an inverse, we need to be careful as to how we implement this step. A naive approach would consists in forming the full Jacobian and directly calling [np.linalg.solve](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html). But we can do better! Using a classical iterative method, all we require is to be able to take matrix-vector products, or more abstractly, to be able to apply an operator to any vector.  \n",
        "\n",
        "In the following, you have to build such method by defining the appropriate operator. Note that this operator has the same form as the policy evalution one, but for $I - A$ and where $A$ need not be a stochastic matrix (but we still need the spectral radius $\\sigma(I - A) < 1$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG7PuddtWxjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def basic_iterative_solver(A, b):\n",
        "  \"\"\" Solves $Ax = b$, assuming that the spectral radius of $I - A$ is \n",
        "  strictly less than 1. We assume that $A$ is a callable $A(v)$.\n",
        "  \"\"\"\n",
        "  def operator(x):\n",
        "    \"\"\" Basic iterative step without preconditioning \n",
        "    (you can add preconditioning if you feel like)\n",
        "\n",
        "    This is what you would obtain by writting the Neumann series epxansion of \n",
        "    $A$ recursively. \n",
        "    \"\"\"\n",
        "    # Add your code here. This is a one-liner\n",
        "    return b + x - A(x)\n",
        "  return successive_approximation(np.zeros(b.shape), operator, default_termination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ38sPm4TTrv",
        "colab_type": "text"
      },
      "source": [
        "Now refer to the course notes or [Rust (1996)](https://doi.org/10.1016/s1574-0021(96)01016-7) for the general structure of Newton-Kantorovich iterations and implement the corresponding operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkZfRM_zSO8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_newton_kantorovich(operator, gateaux_derivative):\n",
        "  \"\"\" Newton-Kantorovich method with matrix-free iterative solver\n",
        "  \"\"\"\n",
        "  def newton_kantorovich(v):\n",
        "    # One-liner using the above basic_iterative_solver\n",
        "    w =  v - operator(v)\n",
        "    A = gateaux_derivative(v)\n",
        "    gd = basic_iterative_solver(A, w)\n",
        "    return np.subtract(v, gd)\n",
        "  return newton_kantorovich"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823YSItRTjEy",
        "colab_type": "text"
      },
      "source": [
        "As usual, we verify that we find the optimal value function when all rewards are one. The following should return true:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VWDl1nhT_pr",
        "colab_type": "code",
        "outputId": "099c6237-d8d0-4864-928c-20c9a976e889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "smooth_operator = make_smooth_bellman_optimality_operator(P, reward_all_ones, discount, default_temperature)\n",
        "gateaux_derivative = make_gateaux_derivative(P, reward_all_ones, discount, default_temperature)\n",
        "\n",
        "newton_kantorovich_operator = make_newton_kantorovich(smooth_operator, gateaux_derivative)\n",
        "solution = successive_approximation(np.zeros((nstates,)), newton_kantorovich_operator, default_termination)\n",
        "print(np.allclose(solution, [1/(1-discount)]*nstates))"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.00000693 -1.00000693]\n",
            "[1.11111881 1.11111881]\n",
            "[-0.88889505 -0.88889505]\n",
            "[-0.79012893 -0.79012893]\n",
            "[-0.70233683 -0.70233683]\n",
            "[-0.6242994 -0.6242994]\n",
            "[-0.5549328 -0.5549328]\n",
            "[-0.4932736 -0.4932736]\n",
            "[-0.43846543 -0.43846543]\n",
            "[-0.38974704 -0.38974704]\n",
            "[-0.34644182 -0.34644182]\n",
            "[-0.30794828 -0.30794828]\n",
            "[-0.27373181 -0.27373181]\n",
            "[-0.24331716 -0.24331716]\n",
            "[-0.21628192 -0.21628192]\n",
            "[-0.1922506 -0.1922506]\n",
            "[-0.17088942 -0.17088942]\n",
            "[-0.15190171 -0.15190171]\n",
            "[-0.13502374 -0.13502374]\n",
            "[-0.1200211 -0.1200211]\n",
            "[-0.10668542 -0.10668542]\n",
            "[-0.09483149 -0.09483149]\n",
            "[-0.08429466 -0.08429466]\n",
            "[-0.07492858 -0.07492858]\n",
            "[-0.06660318 -0.06660318]\n",
            "[-0.05920283 -0.05920283]\n",
            "[-0.05262474 -0.05262474]\n",
            "[-0.04677755 -0.04677755]\n",
            "[-0.04158004 -0.04158004]\n",
            "[-0.03696004 -0.03696004]\n",
            "[-0.03285337 -0.03285337]\n",
            "[-0.02920299 -0.02920299]\n",
            "[-0.02595821 -0.02595821]\n",
            "[-0.02307397 -0.02307397]\n",
            "[-0.02051019 -0.02051019]\n",
            "[-0.01823128 -0.01823128]\n",
            "[-0.01620559 -0.01620559]\n",
            "[-0.01440497 -0.01440497]\n",
            "[-0.01280441 -0.01280441]\n",
            "[-0.0113817 -0.0113817]\n",
            "[-0.01011707 -0.01011707]\n",
            "[-0.00899295 -0.00899295]\n",
            "[-0.00799373 -0.00799373]\n",
            "[-0.00710554 -0.00710554]\n",
            "[-0.00631604 -0.00631604]\n",
            "[-0.00561425 -0.00561425]\n",
            "[-0.00499045 -0.00499045]\n",
            "[-0.00443595 -0.00443595]\n",
            "[-0.00394307 -0.00394307]\n",
            "[-0.00350495 -0.00350495]\n",
            "[-0.00311551 -0.00311551]\n",
            "[-0.00276934 -0.00276934]\n",
            "[-0.00246164 -0.00246164]\n",
            "[-0.00218812 -0.00218812]\n",
            "[-0.001945 -0.001945]\n",
            "[-0.00172889 -0.00172889]\n",
            "[-0.00153679 -0.00153679]\n",
            "[-0.00136604 -0.00136604]\n",
            "[-0.00121425 -0.00121425]\n",
            "[-0.00107934 -0.00107934]\n",
            "[-0.00095941 -0.00095941]\n",
            "[-0.00085281 -0.00085281]\n",
            "[-0.00075805 -0.00075805]\n",
            "[-0.00067382 -0.00067382]\n",
            "[-0.00059896 -0.00059896]\n",
            "[-0.0005324 -0.0005324]\n",
            "[-0.00047325 -0.00047325]\n",
            "[-0.00042067 -0.00042067]\n",
            "[-0.00037392 -0.00037392]\n",
            "[-0.00033238 -0.00033238]\n",
            "[-0.00029545 -0.00029545]\n",
            "[-0.00026262 -0.00026262]\n",
            "[-0.00023344 -0.00023344]\n",
            "[-0.0002075 -0.0002075]\n",
            "[-0.00018445 -0.00018445]\n",
            "[-0.00016395 -0.00016395]\n",
            "[-0.00014574 -0.00014574]\n",
            "[-0.00012954 -0.00012954]\n",
            "[-0.00011515 -0.00011515]\n",
            "[-0.00010235 -0.00010235]\n",
            "[-9.09818524e-05 -9.09818524e-05]\n",
            "[-8.08727678e-05 -8.08727678e-05]\n",
            "[-7.18869137e-05 -7.18869137e-05]\n",
            "[-6.38994868e-05 -6.38994868e-05]\n",
            "[-5.67996149e-05 -5.67996149e-05]\n",
            "[-5.04886096e-05 -5.04886096e-05]\n",
            "[-4.48788202e-05 -4.48788202e-05]\n",
            "[-3.98923345e-05 -3.98923345e-05]\n",
            "[-3.54598972e-05 -3.54598972e-05]\n",
            "[-3.1519948e-05 -3.1519948e-05]\n",
            "[-2.80177666e-05 -2.80177666e-05]\n",
            "[-2.49047126e-05 -2.49047126e-05]\n",
            "[-2.213755e-05 -2.213755e-05]\n",
            "[-1.96778468e-05 -1.96778468e-05]\n",
            "[-1.74914412e-05 -1.74914412e-05]\n",
            "[-1.55479672e-05 -1.55479672e-05]\n",
            "[-1.38204326e-05 -1.38204326e-05]\n",
            "[-1.22848443e-05 -1.22848443e-05]\n",
            "[-1.09198752e-05 -1.09198752e-05]\n",
            "[-9.70656791e-06 -9.70656791e-06]\n",
            "[-8.62807115e-06 -8.62807115e-06]\n",
            "[-7.66940616e-06 -7.66940616e-06]\n",
            "[-6.81725844e-06 -6.81725844e-06]\n",
            "[-6.05986103e-06 -6.05986103e-06]\n",
            "[-5.38661047e-06 -5.38661047e-06]\n",
            "[-4.78815805e-06 -4.78815805e-06]\n",
            "[-4.25619369e-06 -4.25619369e-06]\n",
            "[-3.78333057e-06 -3.78333057e-06]\n",
            "[-3.36300254e-06 -3.36300254e-06]\n",
            "[-2.98937296e-06 -2.98937296e-06]\n",
            "[-2.65725362e-06 -2.65725362e-06]\n",
            "[-2.36203275e-06 -2.36203275e-06]\n",
            "[-2.09961091e-06 -2.09961091e-06]\n",
            "[-1.86634414e-06 -1.86634414e-06]\n",
            "[-1.6589933e-06 -1.6589933e-06]\n",
            "[-1.47467915e-06 -1.47467915e-06]\n",
            "[-1.31084229e-06 -1.31084229e-06]\n",
            "[-1.16520772e-06 -1.16520772e-06]\n",
            "[-1.03575314e-06 -1.03575314e-06]\n",
            "[-9.20680964e-07 -9.20680966e-07]\n",
            "[-8.18393309e-07 -8.18393307e-07]\n",
            "[-7.27469812e-07 -7.27469812e-07]\n",
            "[-6.46647916e-07 -6.46647916e-07]\n",
            "[-5.74869997e-07 -5.74869997e-07]\n",
            "[-5.11059428e-07 -5.11059428e-07]\n",
            "[-4.54331831e-07 -4.54331831e-07]\n",
            "[-4.03900998e-07 -4.03900998e-07]\n",
            "[-3.59067988e-07 -3.59067988e-07]\n",
            "[-3.19211441e-07 -3.19211441e-07]\n",
            "[-2.8377897e-07 -2.8377897e-07]\n",
            "[-2.52279506e-07 -2.52279506e-07]\n",
            "[-2.2427648e-07 -2.2427648e-07]\n",
            "[-1.99381791e-07 -1.99381791e-07]\n",
            "[-1.77250412e-07 -1.77250412e-07]\n",
            "[-1.57575617e-07 -1.57575617e-07]\n",
            "[-1.40084722e-07 -1.40084722e-07]\n",
            "[-1.24535319e-07 -1.24535319e-07]\n",
            "[-1.10711898e-07 -1.10711900e-07]\n",
            "[-9.8422877e-08 -9.8422877e-08]\n",
            "[-8.74979378e-08 -8.74979360e-08]\n",
            "[-7.77856677e-08 -7.77856677e-08]\n",
            "[-6.91514579e-08 -6.91514579e-08]\n",
            "[-6.15447977e-08 -6.15447977e-08]\n",
            "[-5.47748691e-08 -5.47748691e-08]\n",
            "[-4.87496337e-08 -4.87496337e-08]\n",
            "[-4.33871747e-08 -4.33871747e-08]\n",
            "[-3.86145853e-08 -3.86145853e-08]\n",
            "[-3.43669804e-08 -3.43669804e-08]\n",
            "[-3.05866124e-08 -3.05866124e-08]\n",
            "[-2.72220859e-08 -2.72220859e-08]\n",
            "[-2.42276563e-08 -2.42276563e-08]\n",
            "[-2.15626148e-08 -2.15626148e-08]\n",
            "[-1.91907272e-08 -1.91907272e-08]\n",
            "[-1.70797456e-08 -1.70797456e-08]\n",
            "[-1.52009747e-08 -1.52009765e-08]\n",
            "[-1.35288669e-08 -1.35288669e-08]\n",
            "[-1.20406920e-08 -1.20406902e-08]\n",
            "[-1.07162155e-08 -1.07162155e-08]\n",
            "[-9.53743218e-09 -9.53743218e-09]\n",
            "[-8.48831405e-09 -8.48831405e-09]\n",
            "[-7.5546005e-09 -7.5546005e-09]\n",
            "[-6.72359413e-09 -6.72359413e-09]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2MSqa0a73w0",
        "colab_type": "text"
      },
      "source": [
        "# Trajectories in the Polytope\n",
        "\n",
        "Sample $1000$ policies at random. Using either the closed-form expression or via successive approximation, compute the value function corresponding to each of them. Plot the mapping $\\pi \\mapsto v_\\pi$ using [matplotlib.pyplot.scatter](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) (the x axis is $v(s_0)$ and the y axis is $v(s_1))$. Enumerate all possible deterministic policies, compute their value functions and plot them. \n",
        "\n",
        "To do so, you may want to define a new function which generalizes the above ``direct_policy_evaluation`` to the case where you have a batch of policies (let's say as a multidimensional array of size $n \\times |\\mathcal{S}| \\times |\\mathcal{A}|$ where $n$ is the number of policies). This can be done easily by just changing the indices in the Einstein summation since [numpy.linalg.solve](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html) supports *batched*  linear systems out-of-the-box.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS4QqHzOUFlr",
        "colab_type": "code",
        "outputId": "ae3e9a20-2c6d-4f8a-c52a-ae13f38244cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "def batch_policy_evaluation(P, R, discount, policies):\n",
        "\n",
        "  discounted_p_pi = discount * np.einsum('ijk,lji->ljk', P, policies)\n",
        "  a = np.subtract(np.identity(P.shape[-1]), discounted_p_pi)\n",
        "\n",
        "  rpi = np.einsum('ij, lij -> li', R, policies)\n",
        "  return np.linalg.solve(a, rpi)\n",
        "\n",
        "\n",
        "import numpy.random as npr\n",
        "alphas = [0.5, 0.5]\n",
        "policies = npr.dirichlet(alpha=alphas, size=(1000, nstates))\n",
        "#policies = policies / np.sum(policies, axis=-1, keepdims=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vs = batch_policy_evaluation(*mdp, policies)\n",
        "\n",
        "random_int = npr.randint(0,1000)\n",
        "\n",
        "print(\"vs \", vs[random_int,:])\n",
        "print(\"policies \", policies[random_int,:])\n",
        "\n",
        "x = vs[:,0]\n",
        "y = vs[:,1]\n",
        "#xlim_min = min(x)\n",
        "#xlim_max = max(x)\n",
        "#print(xlim_min, xlim_max)\n",
        "\n",
        "#ylim_min = min(y)\n",
        "#ylim_max = max(y)\n",
        "#print(ylim_min, ylim_max)\n",
        "\n",
        "#eps = 1e-1\n",
        "#plt.xlim(xlim_min-eps, xlim_max+eps)\n",
        "#plt.ylim(ylim_min-eps, ylim_max+eps)\n",
        "plt.scatter(x, y)\n",
        "\n",
        "def fill(all_lists, part_list, i):\n",
        "  if i == nstates:\n",
        "    all_lists.append(part_list)\n",
        "  else:\n",
        "    for j in range(nactions):\n",
        "      cur_list = list(part_list)\n",
        "      cur_list.append(j)\n",
        "      fill(all_lists, cur_list, i + 1)\n",
        "\n",
        "deterministic_policies= []\n",
        "fill(deterministic_policies, [], 0)\n",
        "\n",
        "det_policies = []\n",
        "for pol in deterministic_policies:\n",
        "  det_policies += [np.eye(P.shape[-1])[pol]]\n",
        "\n",
        "det_policies = np.stack(det_policies)\n",
        "\n",
        "det_vs = batch_policy_evaluation(*mdp, det_policies)\n",
        "det_x = det_vs[:,0]\n",
        "det_y = det_vs[:,1] \n",
        "\n",
        "plt.scatter(det_x, det_y, c='red')\n",
        "plt.show()\n"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vs  [-2.28834759  0.01520534]\n",
            "policies  [[0.00175009 0.99824991]\n",
            " [0.94387918 0.05612082]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf+FlXV4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKRoPg0qUJU_",
        "colab_type": "text"
      },
      "source": [
        "Overlay (with a different color) the trajectories taken by value iteration, smooth value iteration and Newton-Kantorovich. To do so, compute the greedy policy for each iterate and solve (policy evaluation) for its corresponding value function. Plot all such points.\n",
        "\n",
        "To get those iterates, you can call the function ``generate_iterates`` directly and consume the generator using the ``list()`` keyword:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWuaD7IR3aT_",
        "colab_type": "code",
        "outputId": "b4c953ec-f94a-4aed-d5e8-deef50c608a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "# Example:\n",
        "starting_v = np.array([-2.45884356, -1.77760149])\n",
        "print(starting_v)\n",
        "#print(\"starting_v \", starting_v)\n",
        "bellman_optimality_operator = make_bellman_optimality_operator(*mdp)\n",
        "trajectory = generate_iterates(np.zeros(nstates,), bellman_optimality_operator, default_termination)\n",
        "\n",
        "px = []\n",
        "py = []\n",
        "\n",
        "#new_v = np.add(R, discount * np.einsum('ijk,k->ij', P, starting_v))\n",
        "#print(\"new_v \", new_v)\n",
        "#argmax_a = np.argmax(new_v, axis=1)\n",
        "#print(\"argmax_a \", argmax_a)\n",
        "#pol = np.eye(P.shape[-1])[argmax_a]\n",
        "#print(\"starting v pol \", pol)\n",
        "#policy_evaluation_operator = make_policy_evaluation_operator(*mdp, pol)\n",
        "#pol_v = direct_policy_evaluation(*mdp, pol)\n",
        "\n",
        "#plt.scatter(starting_v[0], starting_v[1], c='black')\n",
        "#plt.scatter(pol_v[0], pol_v[1], c='black')\n",
        "\n",
        "\n",
        "for e in list(trajectory):\n",
        "  #print(\"e \", e)\n",
        "  argmax_a = np.argmax(np.add(R, discount * np.einsum('ijk,k->ji', P, e)), axis=1)\n",
        "  pol = np.eye(P.shape[-1])[argmax_a]\n",
        "  #policy_evaluation_operator = make_policy_evaluation_operator(*mdp, pol)\n",
        "  #pol_v = policy_evaluation_operator(e)\n",
        "  pol_v = direct_policy_evaluation(*mdp, pol)\n",
        "  px.append(e[0])\n",
        "  py.append(e[1])\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.scatter(det_x, det_y, c='red')\n",
        "plt.scatter(px, py, c='black')\n",
        "plt.show()\n",
        "\n",
        "print(\"Done 1\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.45884356 -1.77760149]\n",
            "[-0.25  0.5 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAccgJyIKuP8P1zArzreZnOoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpBdVzD75xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6bf4cae3-fed9-4aa2-920b-bae3f02d2ab9"
      },
      "source": [
        "smooth_bellman_optimality_operator = make_smooth_bellman_optimality_operator(*mdp, default_temperature)\n",
        "smoothtrajectory = generate_iterates(np.zeros((nstates,)), smooth_bellman_optimality_operator, default_termination)\n",
        "\n",
        "smooth_x = []\n",
        "smooth_y = []\n",
        "for e in list(smoothtrajectory):\n",
        "  #print(\"e \", e)\n",
        "\n",
        "  argmax_a = np.argmax(np.add(R, discount * np.einsum('ijk,k->ji', P, e)), axis=1)\n",
        "  pol = np.eye(P.shape[-1])[argmax_a]\n",
        "  pol_v = direct_policy_evaluation(*mdp, pol)\n",
        "  smooth_x.append(e[0])\n",
        "  smooth_y.append(e[1])\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.scatter(det_x, det_y, c='red')\n",
        "plt.scatter(px, py, c='black')\n",
        "plt.scatter(smooth_x, smooth_y, c='green')\n",
        "plt.show()\n",
        "\n",
        "print(\"Done 2\")"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.25  0.5 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBRwDORERAH3/wGd7MwwMdb7qQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsLtDfT83yCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22b85ffe-ca65-4a20-f907-04c68f0c3777"
      },
      "source": [
        "smooth_bellman_optimality_operator = make_smooth_bellman_optimality_operator(*mdp, default_temperature)\n",
        "gateaux_derivative = make_gateaux_derivative(*mdp, default_temperature)\n",
        "newton_kantorovich_operator = make_newton_kantorovich(smooth_bellman_optimality_operator, gateaux_derivative)\n",
        "ntrajectory = generate_iterates(np.zeros((nstates,)), newton_kantorovich_operator, default_termination)\n",
        "\n",
        "nx = []\n",
        "ny = []\n",
        "\n",
        "for e in list(ntrajectory):\n",
        "  #print(\"e \", e)\n",
        "  argmax_a = np.argmax(np.add(R, discount * np.einsum('ijk,k->ij', P, e)), axis=1)\n",
        "  pol = np.eye(P.shape[-1])[argmax_a]\n",
        "  #policy_evaluation_operator = make_policy_evaluation_operator(*mdp, new_pol)\n",
        "  #pol = policy_evaluation_operator(e)\n",
        "  pol_v = direct_policy_evaluation(*mdp, pol)\n",
        "\n",
        "  nx.append(pol_v[0])\n",
        "  ny.append(pol_v[1])\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.scatter(det_x, det_y, c='red')\n",
        "plt.scatter(px, py, c='black')\n",
        "plt.scatter(smooth_x, smooth_y, c='green')\n",
        "plt.scatter(nx, ny, c='yellow')\n",
        "plt.show()\n",
        "\n",
        "print(\"Done 3\")"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.25 -0.5 ]\n",
            "[-0.2883263   0.76652602]\n",
            "[ 0.2116737  -0.23347398]\n",
            "[ 0.06881069 -0.08231508]\n",
            "[-0.01516108 -0.01210804]\n",
            "[-0.01193458 -0.01199625]\n",
            "[-0.01063966 -0.01063842]\n",
            "[-0.00945685 -0.00945687]\n",
            "[-0.0084061 -0.0084061]\n",
            "[-0.00747209 -0.00747209]\n",
            "[-0.00664186 -0.00664186]\n",
            "[-0.00590387 -0.00590387]\n",
            "[-0.00524789 -0.00524789]\n",
            "[-0.00466479 -0.00466479]\n",
            "[-0.00414648 -0.00414648]\n",
            "[-0.00368576 -0.00368576]\n",
            "[-0.00327623 -0.00327623]\n",
            "[-0.00291221 -0.00291221]\n",
            "[-0.00258863 -0.00258863]\n",
            "[-0.002301 -0.002301]\n",
            "[-0.00204533 -0.00204533]\n",
            "[-0.00181808 -0.00181808]\n",
            "[-0.00161607 -0.00161607]\n",
            "[-0.0014365 -0.0014365]\n",
            "[-0.00127689 -0.00127689]\n",
            "[-0.00113502 -0.00113502]\n",
            "[-0.0010089 -0.0010089]\n",
            "[-0.0008968 -0.0008968]\n",
            "[-0.00079716 -0.00079716]\n",
            "[-0.00070858 -0.00070858]\n",
            "[-0.00062985 -0.00062985]\n",
            "[-0.00055987 -0.00055987]\n",
            "[-0.00049766 -0.00049766]\n",
            "[-0.00044237 -0.00044237]\n",
            "[-0.00039321 -0.00039321]\n",
            "[-0.00034952 -0.00034952]\n",
            "[-0.00031069 -0.00031069]\n",
            "[-0.00027617 -0.00027617]\n",
            "[-0.00024548 -0.00024548]\n",
            "[-0.00021821 -0.00021821]\n",
            "[-0.00019396 -0.00019396]\n",
            "[-0.00017241 -0.00017241]\n",
            "[-0.00015325 -0.00015325]\n",
            "[-0.00013623 -0.00013623]\n",
            "[-0.00012109 -0.00012109]\n",
            "[-0.00010763 -0.00010763]\n",
            "[-9.56752873e-05 -9.56752873e-05]\n",
            "[-8.50447104e-05 -8.50447104e-05]\n",
            "[-7.55953076e-05 -7.55953076e-05]\n",
            "[-6.71958374e-05 -6.71958374e-05]\n",
            "[-5.97297079e-05 -5.97297079e-05]\n",
            "[-5.309314e-05 -5.309314e-05]\n",
            "[-4.71939612e-05 -4.71939612e-05]\n",
            "[-4.19502402e-05 -4.19502402e-05]\n",
            "[-3.7289149e-05 -3.7289149e-05]\n",
            "[-3.31459517e-05 -3.31459517e-05]\n",
            "[-2.9463105e-05 -2.9463105e-05]\n",
            "[-2.61894594e-05 -2.61894594e-05]\n",
            "[-2.32795486e-05 -2.32795486e-05]\n",
            "[-2.06929579e-05 -2.06929579e-05]\n",
            "[-1.83937634e-05 -1.83937634e-05]\n",
            "[-1.63500323e-05 -1.63500323e-05]\n",
            "[-1.45333802e-05 -1.45333802e-05]\n",
            "[-1.29185763e-05 -1.29185763e-05]\n",
            "[-1.14831933e-05 -1.14831933e-05]\n",
            "[-1.02072957e-05 -1.02072957e-05]\n",
            "[-9.07316309e-06 -9.07316309e-06]\n",
            "[-8.06504394e-06 -8.06504394e-06]\n",
            "[-7.16893691e-06 -7.16893691e-06]\n",
            "[-6.37239633e-06 -6.37239633e-06]\n",
            "[-5.6644231e-06 -5.6644231e-06]\n",
            "[-5.03510569e-06 -5.03510569e-06]\n",
            "[-4.47570545e-06 -4.47570545e-06]\n",
            "[-3.97845457e-06 -3.97845457e-06]\n",
            "[-3.53644827e-06 -3.53644827e-06]\n",
            "[-3.14354887e-06 -3.14354887e-06]\n",
            "[-2.79430059e-06 -2.79430059e-06]\n",
            "[-2.48385379e-06 -2.48385379e-06]\n",
            "[-2.20789764e-06 -2.20789764e-06]\n",
            "[-1.96260021e-06 -1.96260021e-06]\n",
            "[-1.74455533e-06 -1.74455533e-06]\n",
            "[-1.55073523e-06 -1.55073523e-06]\n",
            "[-1.37844854e-06 -1.37844855e-06]\n",
            "[-1.22530291e-06 -1.22530291e-06]\n",
            "[-1.08917176e-06 -1.08917176e-06]\n",
            "[-9.68164776e-07 -9.68164776e-07]\n",
            "[-8.60601669e-07 -8.60601669e-07]\n",
            "[-7.64988824e-07 -7.64988824e-07]\n",
            "[-6.79998566e-07 -6.79998566e-07]\n",
            "[-6.04518725e-07 -6.04518725e-07]\n",
            "[-5.37417146e-07 -5.37417147e-07]\n",
            "[-4.77763843e-07 -4.77763843e-07]\n",
            "[-4.24732056e-07 -4.24732057e-07]\n",
            "[-3.77586798e-07 -3.77586798e-07]\n",
            "[-3.35674664e-07 -3.35674664e-07]\n",
            "[-2.98414776e-07 -2.98414776e-07]\n",
            "[-2.65290736e-07 -2.65290736e-07]\n",
            "[-2.35843464e-07 -2.35843464e-07]\n",
            "[-2.09664839e-07 -2.09664839e-07]\n",
            "[-1.86392042e-07 -1.86392042e-07]\n",
            "[-1.65702526e-07 -1.65702525e-07]\n",
            "[-1.47309545e-07 -1.47309545e-07]\n",
            "[-1.30958186e-07 -1.30958186e-07]\n",
            "[-1.16421827e-07 -1.16421827e-07]\n",
            "[-1.03499004e-07 -1.03499004e-07]\n",
            "[-9.20106148e-08 -9.20106153e-08]\n",
            "[-8.17974369e-08 -8.17974362e-08]\n",
            "[-7.27179209e-08 -7.27179210e-08]\n",
            "[-6.46462317e-08 -6.46462321e-08]\n",
            "[-5.75351464e-08 -5.75351466e-08]\n",
            "[-5.12062805e-08 -5.12062801e-08]\n",
            "[-4.55735893e-08 -4.55735896e-08]\n",
            "[-4.05604946e-08 -4.05604945e-08]\n",
            "[-3.60988403e-08 -3.60988404e-08]\n",
            "[-3.21279677e-08 -3.21279678e-08]\n",
            "[-2.85938915e-08 -2.85938913e-08]\n",
            "[-2.54485634e-08 -2.54485635e-08]\n",
            "[-2.26492213e-08 -2.26492214e-08]\n",
            "[-2.01578071e-08 -2.01578068e-08]\n",
            "[-1.79404481e-08 -1.79404480e-08]\n",
            "[-1.59669988e-08 -1.59669993e-08]\n",
            "[-1.42106291e-08 -1.42106289e-08]\n",
            "[-1.26474599e-08 -1.26474597e-08]\n",
            "[-1.12562392e-08 -1.12562391e-08]\n",
            "[-1.00180528e-08 -1.00180531e-08]\n",
            "[-8.91606711e-09 -8.91606722e-09]\n",
            "[-7.93529975e-09 -7.93529953e-09]\n",
            "[-7.06241687e-09 -7.06241665e-09]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD0bYgi1-TQ-",
        "colab_type": "code",
        "outputId": "87b31ac2-b91a-4064-cfd4-d44259f9be2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.scatter(px, py)\n",
        "\n",
        "plt.scatter(nx, ny, c='green')\n",
        "\n",
        "plt.scatter(smooth_x, smooth_y, c='red')\n",
        "\n",
        "\n",
        "#plt.scatter(nx, ny, c='green')\n",
        "plt.show()"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04jm7-x1APoo",
        "colab_type": "text"
      },
      "source": [
        "Describes what happens as you decrease the temperature in smooth value iteration and with Newton-Kantorovich and the smooth Bellman operator? Answer this question by creating a new polytope plot on which you overlays the different trajectories taken by your algorithm depending on the temperature parameter. Don't forget to add a legend. \n",
        "\n",
        "Also, compare the trajectories taken by policy iteration and the Newton-Kantorovich method. Do they match? Compare the iterates computed by smooth policy iteration and those of the Newton-Kantorovich method with the smooth operator using the ``generate_iterates`` function. For each iterate of smooth policy iteration (a policy), compute the associated value function and compare with the values produced by Newton-Kantorovich. Do you get the same sequence of values as if you were to run Newton-Kantorovich? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FccNFU_t6Ami",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}